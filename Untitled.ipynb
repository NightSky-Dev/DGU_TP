{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>WIN</th>\n",
       "      <th>WINRATE</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SLG</th>\n",
       "      <th>RBI/AB</th>\n",
       "      <th>R/AB</th>\n",
       "      <th>SB</th>\n",
       "      <th>LP/AB</th>\n",
       "      <th>AVGP</th>\n",
       "      <th>SLGP</th>\n",
       "      <th>K/AB</th>\n",
       "      <th>BB/AB</th>\n",
       "      <th>Err/AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19670410</td>\n",
       "      <td>NYA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19670410</td>\n",
       "      <td>WS2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19670410</td>\n",
       "      <td>LAN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19670410</td>\n",
       "      <td>CIN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19670411</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE TEAM  WIN  WINRATE    AVG    SLG  RBI/AB   R/AB   SB  LP/AB  \\\n",
       "0  19670410  NYA    1      1.0  0.513  0.154   0.205  0.205  0.0  0.000   \n",
       "1  19670410  WS2    0      0.0  0.067  0.000   0.000  0.000  0.0  0.205   \n",
       "2  19670410  LAN    0      0.0  0.219  0.031   0.031  0.031  0.0  0.194   \n",
       "3  19670410  CIN    1      1.0  0.452  0.129   0.194  0.194  1.0  0.031   \n",
       "4  19670411  MIN    0      0.0  0.353  0.088   0.088  0.088  0.0  0.200   \n",
       "\n",
       "    AVGP   SLGP   K/AB  BB/AB  Err/AB  \n",
       "0  0.067  0.000  0.200  0.100   0.026  \n",
       "1  0.513  0.154  0.154  0.077   0.067  \n",
       "2  0.452  0.129  0.065  0.129   0.000  \n",
       "3  0.219  0.031  0.156  0.062   0.000  \n",
       "4  0.367  0.133  0.167  0.100   0.059  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "URL = 'C:\\\\Users\\\\User\\\\Desktop\\\\NightSky\\\\Project NightSky\\\\datasets_02.csv'\n",
    "dataframe1 = pd.read_csv(URL)\n",
    "dataframe1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>WIN</th>\n",
       "      <th>WINRATE</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SLG</th>\n",
       "      <th>RBI/AB</th>\n",
       "      <th>R/AB</th>\n",
       "      <th>SB</th>\n",
       "      <th>LP/AB</th>\n",
       "      <th>AVGP</th>\n",
       "      <th>SLGP</th>\n",
       "      <th>K/AB</th>\n",
       "      <th>BB/AB</th>\n",
       "      <th>Err/AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19670411</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19670411</td>\n",
       "      <td>KC1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19670412</td>\n",
       "      <td>CHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19670412</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19670412</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE TEAM  WIN  WINRATE    AVG    SLG  RBI/AB   R/AB     SB  LP/AB  \\\n",
       "0  19670411  CLE    0        0  0.212  0.061   0.091  0.091  0.000  0.129   \n",
       "1  19670411  KC1    1        0  0.323  0.000   0.097  0.129  0.500  0.091   \n",
       "2  19670412  CHA    0        0  0.250  0.031   0.031  0.125  0.667  0.167   \n",
       "3  19670412  BOS    1        0  0.300  0.067   0.133  0.167  1.000  0.125   \n",
       "4  19670412  PHI    1        0  0.244  0.049   0.098  0.122  0.000  0.100   \n",
       "\n",
       "    AVGP   SLGP   K/AB  BB/AB  Err/AB  \n",
       "0  0.323  0.000  0.290  0.290   0.030  \n",
       "1  0.212  0.061  0.182  0.091   0.065  \n",
       "2  0.300  0.067  0.133  0.267   0.031  \n",
       "3  0.250  0.031  0.219  0.125   0.033  \n",
       "4  0.350  0.075  0.025  0.125   0.073  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = 'C:\\\\Users\\\\User\\\\Desktop\\\\NightSky\\\\Project NightSky\\\\datasets_even.csv'\n",
    "dataframe2=pd.read_csv(testdata)\n",
    "dataframe2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>WIN</th>\n",
       "      <th>WINRATE</th>\n",
       "      <th>AVG</th>\n",
       "      <th>SLG</th>\n",
       "      <th>RBI/AB</th>\n",
       "      <th>R/AB</th>\n",
       "      <th>SB</th>\n",
       "      <th>LP/AB</th>\n",
       "      <th>AVGP</th>\n",
       "      <th>SLGP</th>\n",
       "      <th>K/AB</th>\n",
       "      <th>BB/AB</th>\n",
       "      <th>Err/AB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DOO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196455</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.127031</td>\n",
       "      <td>0.100443</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KIW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.174298</td>\n",
       "      <td>0.196455</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.146875</td>\n",
       "      <td>0.073438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DATE TEAM  WIN  WINRATE    AVG    SLG    RBI/AB      R/AB        SB  \\\n",
       "0     1  DOO  NaN    0.704  0.269  0.319  0.112500  0.121875  0.000000   \n",
       "1     1  KIW  NaN    0.537  0.318  0.380  0.174298  0.196455  0.055556   \n",
       "\n",
       "      LP/AB   AVGP   SLGP      K/AB     BB/AB  Err/AB  \n",
       "0  0.196455  0.316  0.412  0.127031  0.100443       0  \n",
       "1  0.121875  0.265  0.317  0.146875  0.073438       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rkbodata='C:\\\\Users\\\\User\\\\Desktop\\\\NightSky\\\\Project NightSky\\\\RKBO_03.csv'\n",
    "dataframe3=pd.read_csv(rkbodata)\n",
    "dataframe3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106921 훈련 샘플\n",
      "26731 검증 샘플\n",
      "31615 테스트 샘플\n",
      "전체 특성: ['DATE', 'TEAM', 'WINRATE', 'AVG', 'SLG', 'RBI/AB', 'R/AB', 'SB', 'LP/AB', 'AVGP', 'SLGP', 'K/AB', 'BB/AB', 'Err/AB']\n",
      "타율 특성의 배치: tf.Tensor([0.419 0.457 0.22  ... 0.353 0.129 0.308], shape=(1024,), dtype=float64)\n",
      "타깃의 배치: tf.Tensor([1 1 0 ... 1 0 1], shape=(1024,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train, val = train_test_split(dataframe1, test_size=0.2)\n",
    "#test=dataframe2\n",
    "predict=dataframe3\n",
    "trash, test = train_test_split(dataframe2,test_size=0.8)\n",
    "print(len(train), '훈련 샘플')\n",
    "print(len(val), '검증 샘플')\n",
    "print(len(test), '테스트 샘플')\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('WIN')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "batch_size = 1024\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "predict_ds=df_to_dataset(predict,shuffle=False,batch_size=batch_size)\n",
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('전체 특성:', list(feature_batch.keys()))\n",
    "  print('타율 특성의 배치:', feature_batch['AVG'])\n",
    "  print('타깃의 배치:', label_batch )\n",
    "\n",
    "feature_columns = []\n",
    "for header in ['WINRATE', 'AVG', 'SLG','R/AB','SB','LP/AB','AVGP','SLGP','RBI/AB','K/AB','BB/AB','Err/AB']: #\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "batch_size = 1024\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "predict_ds=df_to_dataset(predict,shuffle=False,batch_size=batch_size)\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1= tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dense(100,activation='relu'),\n",
    "  layers.Dense(100, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'DATE': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'TEAM': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'WINRATE': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'AVG': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'SLG': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'RBI/AB': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'R/AB': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'SB': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'LP/AB': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'AVGP': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'SLGP': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'K/AB': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'BB/AB': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Err/AB': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'DATE': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'TEAM': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'WINRATE': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'AVG': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'SLG': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'RBI/AB': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'R/AB': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'SB': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'LP/AB': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'AVGP': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'SLGP': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'K/AB': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'BB/AB': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Err/AB': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "104/105 [============================>.] - ETA: 0s - loss: 0.1564 - accuracy: 0.9568WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'DATE': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'TEAM': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'WINRATE': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=float64>, 'AVG': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'SLG': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'RBI/AB': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'R/AB': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'SB': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'LP/AB': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'AVGP': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'SLGP': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'K/AB': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'BB/AB': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Err/AB': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.1559 - accuracy: 0.9570 - val_loss: 0.2352 - val_accuracy: 0.9605\n",
      "Epoch 2/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0153 - accuracy: 0.9971 - val_loss: 0.0786 - val_accuracy: 0.9917\n",
      "Epoch 3/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0262 - val_accuracy: 0.9963\n",
      "Epoch 4/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0088 - val_accuracy: 0.9984\n",
      "Epoch 5/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 6/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 7/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 8/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 9/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
      "Epoch 10/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 11/200\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 12/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 13/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 14/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 15/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 16/200\n",
      "105/105 [==============================] - 1s 13ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 17/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 18/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 19/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 20/200\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 21/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 22/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 23/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 24/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 25/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 26/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "Epoch 27/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 28/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 29/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 30/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 31/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0033 - val_accuracy: 0.9989\n",
      "Epoch 32/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 33/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 34/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 35/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 36/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 37/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 38/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 39/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 40/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 41/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 42/200\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 43/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 44/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 45/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 46/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 47/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 48/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 49/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 50/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0034 - val_accuracy: 0.9988\n",
      "Epoch 51/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 52/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 53/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 54/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 55/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 56/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 57/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 58/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 59/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 60/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 61/200\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 62/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 63/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 64/200\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 65/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 66/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 67/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 68/200\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 69/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 70/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 71/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 72/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 73/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 74/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
      "Epoch 75/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 76/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 77/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9986\n",
      "Epoch 78/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 79/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9989\n",
      "Epoch 80/200\n",
      "105/105 [==============================] - 1s 14ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 81/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 82/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 83/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0036 - val_accuracy: 0.9988\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0040 - val_accuracy: 0.9989\n",
      "Epoch 85/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 86/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 87/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 88/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 89/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 90/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
      "Epoch 91/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 92/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 93/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 94/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 95/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "Epoch 96/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 97/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 98/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 99/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 100/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 101/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "Epoch 102/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 103/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 104/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 105/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 106/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 107/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9988\n",
      "Epoch 108/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 109/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9985\n",
      "Epoch 110/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 111/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 112/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 113/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 114/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 115/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 116/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 117/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 118/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 119/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 120/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 121/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "Epoch 122/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 123/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 124/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 125/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 126/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
      "Epoch 127/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 128/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 129/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 130/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 131/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9987\n",
      "Epoch 132/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 133/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9987\n",
      "Epoch 134/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 135/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 136/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 137/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9986\n",
      "Epoch 138/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 139/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 140/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 141/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 142/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
      "Epoch 143/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 144/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 145/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
      "Epoch 146/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9987\n",
      "Epoch 147/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0051 - val_accuracy: 0.9988\n",
      "Epoch 148/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
      "Epoch 149/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 150/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 151/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 152/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 153/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 154/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 155/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
      "Epoch 156/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9984\n",
      "Epoch 157/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 158/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 159/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 160/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0053 - val_accuracy: 0.9986\n",
      "Epoch 161/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 162/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 163/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0058 - val_accuracy: 0.9984\n",
      "Epoch 164/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 165/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 166/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
      "Epoch 167/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 168/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9984\n",
      "Epoch 169/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9987\n",
      "Epoch 170/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
      "Epoch 171/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 172/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9984\n",
      "Epoch 173/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0051 - val_accuracy: 0.9986\n",
      "Epoch 174/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0052 - val_accuracy: 0.9986\n",
      "Epoch 175/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 176/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 177/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 178/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0088 - val_accuracy: 0.9976\n",
      "Epoch 179/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 180/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 181/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9987\n",
      "Epoch 182/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9980\n",
      "Epoch 183/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 184/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
      "Epoch 185/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
      "Epoch 186/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 187/200\n",
      "105/105 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 188/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
      "Epoch 189/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 190/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0054 - val_accuracy: 0.9986\n",
      "Epoch 191/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 192/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
      "Epoch 193/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0058 - val_accuracy: 0.9986\n",
      "Epoch 194/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "Epoch 195/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9984\n",
      "Epoch 197/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9986\n",
      "Epoch 198/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 0.9986\n",
      "Epoch 199/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
      "Epoch 200/200\n",
      "105/105 [==============================] - 1s 11ms/step - loss: 8.2230e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9986\n"
     ]
    }
   ],
   "source": [
    "DNN1=model1.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features (DenseFeature multiple                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  48        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  101       \n",
      "=================================================================\n",
      "Total params: 11,549\n",
      "Trainable params: 11,525\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'DATE': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=int64>, 'TEAM': <tf.Tensor 'ExpandDims_12:0' shape=(None, 1) dtype=string>, 'WINRATE': <tf.Tensor 'ExpandDims_13:0' shape=(None, 1) dtype=int64>, 'AVG': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'SLG': <tf.Tensor 'ExpandDims_10:0' shape=(None, 1) dtype=float64>, 'RBI/AB': <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=float64>, 'R/AB': <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=float64>, 'SB': <tf.Tensor 'ExpandDims_9:0' shape=(None, 1) dtype=float64>, 'LP/AB': <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=float64>, 'AVGP': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float64>, 'SLGP': <tf.Tensor 'ExpandDims_11:0' shape=(None, 1) dtype=float64>, 'K/AB': <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float64>, 'BB/AB': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>, 'Err/AB': <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9868\n",
      "1 정확도 0.987\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "loss1, accuracy1 = model1.evaluate(test_ds)\n",
    "print(\"1 정확도\", round(accuracy1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(histories, key='loss'):\n",
    "  plt.figure(figsize=(16,10))\n",
    "\n",
    "  for name, history in histories:\n",
    "    val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                   '--', label=name.title()+' Val_loss')\n",
    "    plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "             label=name.title()+' Train_loss')\n",
    "\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel(key.replace('_',' ').title())\n",
    "  plt.legend()\n",
    "\n",
    "  plt.xlim([0,max(history.epoch)])\n",
    "\n",
    "\n",
    "plot_history([('DNN1', DNN1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf23] *",
   "language": "python",
   "name": "conda-env-tf23-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
